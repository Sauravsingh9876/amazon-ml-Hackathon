# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VWDJ82Ch5hIIZWCnW3d6WqUXgmvk5B_3
"""

import pandas as pd





!pip install pandas scikit-learn opencv-python pytesseract torch torchvision transformers

from google.colab import drive
drive.mount('/content/drive')

train_data = pd.read_csv('/content/drive/MyDrive/amazon/dataset/train.csv')
test_data = pd.read_csv('/content/drive/MyDrive/amazon/dataset/test.csv')

# Check the first few rows of the training data
train_data.head()

!pip install opencv-python matplotlib requests

import pandas as pd
import requests
import os

# Load your CSV file
csv_path = '/content/drive/MyDrive/amazon/dataset/train.csv'  # Replace with your actual CSV file path
data = pd.read_csv(csv_path)

# Create a directory to save the images
os.makedirs('images', exist_ok=True)

# Function to download an image
def download_image(image_url, image_name):
    img_data = requests.get(image_url).content
    with open(image_name, 'wb') as handler:
        handler.write(img_data)

# Iterate through the CSV file and download each image
for index, row in data.iterrows():
    image_url = row['image_link']  # Replace 'image_link' with the actual column name for the image URLs
    image_name = f"images/image_{index}.jpg"
    download_image(image_url, image_name)
    print(f"Downloaded: {image_name}")

import cv2
import matplotlib.pyplot as plt

# Function to preprocess images
def preprocess_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    # Apply thresholding to binarize the image
    _, img_bin = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    return img_bin

# Apply the function to one of the downloaded images
image_path = 'images/image_0.jpg'  # Replace with one of the downloaded images
processed_image = preprocess_image(image_path)

# Display the processed image
plt.imshow(processed_image, cmap='GnBu')
plt.show()

import cv2
import matplotlib.pyplot as plt

# Function to preprocess images
def preprocess_image(image_path):
    # Check if the file exists to prevent errors
    if not os.path.exists(image_path):
        print(f"Error: Image file not found: {image_path}")
        return None  # Return None to indicate an error

    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    if img is None:
        print(f"Error: Could not read image: {image_path}")
        return None

    # Apply thresholding to binarize the image
    _, img_bin = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    return img_bin

for index in range(len(data)):
    image_path = f"images/image_{index}.jpg"
    processed_image = preprocess_image(image_path)

    if processed_image is not None: # Check if image was processed successfully
        # Optionally display or save the processed image
        # Example to display
        plt.imshow(processed_image, cmap='gray')
        plt.show()

        # Save the processed image if needed
        processed_image_path = f"images/processed_image_{index}.jpg"
        cv2.imwrite(processed_image_path, processed_image)
        print(f"Processed and saved: {processed_image_path}")

!pip install pytesseract

!sudo apt-get install tesseract-ocr

import pytesseract
from PIL import Image

# Extract text from image using Tesseract OCR
def extract_text_from_image(image_path):
    # Open the image
    img = Image.open(image_path)

    # Perform OCR to extract text
    extracted_text = pytesseract.image_to_string(img)

    return extracted_text

# Process all images and extract text
for index in range(len(data)):
    processed_image_path = f"images/processed_image_{index}.jpg"

    # Check if the file exists
    if os.path.isfile(processed_image_path):
        # Extract text from the preprocessed image
        extracted_text = extract_text_from_image(processed_image_path)

        # Print the extracted text (for debugging purposes)
        print(f"Extracted text from image {index}: {extracted_text}")

        # Optionally, store the extracted text in a list or file for further analysis
    else:
        print(f"Processed image {index} not found")

import re
from PIL import Image
import pytesseract
import os

# Define allowed units for each entity type (from constants.py or appendix)
allowed_units = ["gram", "kilogram", "cm", "millimeter", "inch", "ounce", "liter", "milliliter"]

# Function to extract entity values and units from text
def extract_entity_value(text):
    # Regular expression to match numbers followed by units
    entity_pattern = r'(\d+(\.\d+)?\s?(gram|kilogram|cm|millimeter|inch|ounce|liter|milliliter))'

    # Search for the pattern in the text
    match = re.search(entity_pattern, text)

    if match:
        # Extract the entity value and unit
        entity_value = match.group(0)
        return entity_value
    else:
        return ""  # Return empty string if no match is found

# Example usage with extracted text
# Check if data is defined and is not empty
if 'data' in globals() and len(data) > 0:
    for index in range(len(data)):
        processed_image_path = f"images/processed_image_{index}.jpg"

        # Check if the file exists
        if os.path.isfile(processed_image_path):
            # Extract text from image
            extracted_text = extract_text_from_image(processed_image_path)

            # Extract entity value and unit from the text
            entity_value = extract_entity_value(extracted_text)

# Convert grams to kilograms
def normalize_units(value, unit):
    if unit == "gram":
        return value / 1000, "kilogram"
    elif unit == "cm":
        return value, "centimeter"  # For example, just return the same value
    # Add more conversions as needed
    return value, unit  # Return unchanged if no conversion is needed

# Example usage
value, unit = 500, "gram"
normalized_value, normalized_unit = normalize_units(value, unit)
print(f"Normalized: {normalized_value} {normalized_unit}")  # Output: 0.5 kilogram

import pandas as pd
import os # import os module

# List to store results
predictions = []

for index in range(len(data)):
    processed_image_path = f"images/processed_image_{index}.jpg"

    # Check if file exists
    if os.path.exists(processed_image_path):
        # Extract text from image
        extracted_text = extract_text_from_image(processed_image_path)

        # Extract entity value and unit from the text
        entity_value = extract_entity_value(extracted_text)

        # Store the result in the required format
        predictions.append({
            'index': index,
            'prediction': entity_value
        })
    else:
        print(f"File not found: {processed_image_path}")

# Convert the results into a DataFrame
output_df = pd.DataFrame(predictions)

# Save the predictions to a CSV file
output_df.to_csv('output.csv', index=False)

print("Predictions saved to output.csv")

!cd /path/to/your/directory
!python src/sanity.py output.csv
